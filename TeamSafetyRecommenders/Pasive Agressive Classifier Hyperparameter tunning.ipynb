{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passive Agressive Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to do a separate hyperparameter tunning with this classifiers, since the clasification graphic showed a good score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "%matplotlib notebook\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import csv\n",
    "from numpy import nan as NA\n",
    "from datetime import datetime\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from pandas import *\n",
    "import pickle\n",
    "import requests\n",
    "import os\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    102462\n",
       "7     82325\n",
       "4     26379\n",
       "5     23033\n",
       "8     22602\n",
       "3     17686\n",
       "2      2170\n",
       "1       942\n",
       "9       196\n",
       "Name: ucr-rank, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('x_y_z.pickle', 'rb') as xyz:\n",
    "    feat_var = pickle.load(xyz)\n",
    "X =  feat_var[0]\n",
    "y =  feat_var[1] #y is \"offense group\"\n",
    "z =  feat_var[2] # z is \"ucr-rank\"\n",
    "z_i = pd.Series(z)\n",
    "z_i.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[[\"hour\",\"street\", \"month\", \"day\", \"LATITUDE\", \"LONGITUDE\", \"Temperature\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    230618\n",
       "1     47177\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_i = pd.Series(y)\n",
    "y_i.value_counts()  # 0 non violent, 1 violent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 461236 entries, 0 to 461235\n",
      "Data columns (total 7 columns):\n",
      "0    461236 non-null int64\n",
      "1    461236 non-null int64\n",
      "2    461236 non-null int64\n",
      "3    461236 non-null int64\n",
      "4    461236 non-null int64\n",
      "5    461236 non-null int64\n",
      "6    461236 non-null int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 24.6 MB\n",
      "None\n",
      "1    230618\n",
      "0    230618\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_res_i = pd.DataFrame(X_res)\n",
    "y_res_i = pd.Series(y_res)\n",
    "\n",
    "print (X_res_i.info())\n",
    "print (y_res_i.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\franc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_res, y_res, test_size=0.2,random_state= 0)\n",
    "scaler = StandardScaler()\n",
    "#scaler =  MinMaxScaler()\n",
    "#scaler = Normalizer()\n",
    "X_train = scaler.fit(X_train).transform(X_train)\n",
    "X_test = scaler.fit(X_test).transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(model, parameters):\n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'accuracy', cv = 4, n_jobs = -1, verbose = 10)\n",
    "    grid_search = grid_search.fit(X_train, y_train)\n",
    "    accuracy = grid_search.best_score_\n",
    "    best_params = grid_search.best_params_\n",
    "    return accuracy, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_params = [{'C':[1, 3, 5, 10, 30, 50, 100, 200], 'fit_intercept': [True, False], 'max_iter': [5,10,20,50, 100]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 80 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "scores_dict = {'accuracy': [], 'best_params': []}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pas = PassiveAggressiveClassifier()\n",
    "    acu, best_params = gridsearch(pas, list_params)\n",
    "    scores_dict['accuracy'].append(acu)\n",
    "    scores_dict['best_params'].append(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': [0.5735525274534673], 'best_params': [{'C': 1, 'fit_intercept': False, 'max_iter': 10}]}\n"
     ]
    }
   ],
   "source": [
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
